{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prithikaeng/prithika.c/blob/main/Medical_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA9ZK9VN1QTj",
        "outputId": "3aa703ff-5a12-46b8-8a73-a31567013ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "\n",
            "üîç Searching PubMed for related research...\n",
            "üìö Building knowledge base from PubMed articles...\n",
            "ü§ñ Connecting to Gemini for answer generation...\n",
            "\n",
            "ü©∫ Answer:\n",
            "\n",
            "Based on the provided context, injections were used in several ways:\n",
            "\n",
            "1. **Intracranial injection:**  Used to administer cerebrospinal fluid tracers and fluorescent magnetic beads to assess solute clearance efficiency in a study on Intracerebral Hemorrhage (ICH).\n",
            "2. **Intranasal administration:** Used to deliver interventions to mice with ICH.\n",
            "3. **Intravitreal injection:** Mentioned in the context of administering gas and Tissue plasminogen activator for submacular hemorrhage.  Also mentioned in the context of aflibercept injections for macular edema.\n",
            "\n",
            "\n",
            "It's important to note that \"injection\" itself is a broad term referring to the act of introducing a substance into the body using a syringe and needle. The specific type of injection is determined by the target location (e.g., intracranial, intranasal, intravitreal).\n",
            "\n",
            "üìö Sources:\n",
            "\n",
            "Source 1:\n",
            "METHODS: Hemin, an iron-rich porphyrin compound, was used to construct the in \n",
            "vitro model of ICH. Primary astrocytes were treated with complete medium \n",
            "supplemented with different concentrations of hemin to obtain exosomes secreted \n",
            "by them, and mice with ICH induced by the collagenase method were intervened by \n",
            "intranasal administration. Solute clearance efficiency was assessed by \n",
            "intracranial injection of cerebrospinal fluid tracers and fluorescent magnetic \n",
            "beads. Immunofluorescence analysi...\n",
            "\n",
            "Source 2:\n",
            "1. Trials. 2025 Apr 14;26(1):131. doi: 10.1186/s13063-025-08727-8.\n",
            "\n",
            "Vitrectomy, subretinal Tissue plasminogen activator and Intravitreal Gas for \n",
            "submacular haemorrhage secondary to Exudative Age-Related macular degeneration \n",
            "(TIGER): update to study protocol and addition of a statistical analysis plan \n",
            "and health economic analysis plan for a randomised controlled surgical trial.\n",
            "\n",
            "Lee CN(1), Desai R(1), Ramazzotto L(2), Wafa H(3), Wang Y(3), Bunce C(4), \n",
            "Doungsong K(5), Ezeofor V(5), Edwards RT(...\n",
            "\n",
            "Source 3:\n",
            "BACKGROUND: Macular edema (ME) is a prevalent complication of diabetic \n",
            "retinopathy (DR) and retinal vein occlusion (RVO) that contributes significantly \n",
            "to vision impairment worldwide. This condition is primarily driven by elevated \n",
            "vascular endothelial growth factor (VEGF) and pro-inflammatory cytokines, \n",
            "resulting in the use of anti-VEGF agents such as aflibercept and corticosteroids \n",
            "such as dexamethasone implants. However, evidence comparing the clinical \n",
            "efficacy and safety of these two mo...\n",
            "\n",
            "Source 4:\n",
            "¬© 2025. Crown.\n",
            "\n",
            "DOI: 10.1186/s13063-025-08727-8\n",
            "PMID: 40229856 [Indexed for MEDLINE]...\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Step 1: Install dependencies\n",
        "!pip install -U langchain-community\n",
        "!pip install -q langchain faiss-cpu langchain-google-genai biopython google-generativeai\n",
        "\n",
        "# ‚úÖ Step 2: Import necessary libraries\n",
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from Bio import Entrez\n",
        "\n",
        "# ‚úÖ Step 3: API keys\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCgdbltYrrLWBO6dKVvfGfK-qvzMipTke4\" # Replace with your Gemini API key\n",
        "Entrez.email = \"prithika2004c@gmail.com\"  # Replace with your email for PubMed\n",
        "\n",
        "# ‚úÖ Step 4: Fetch articles from PubMed\n",
        "def fetch_pubmed_articles(query, max_results=5):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
        "    record = Entrez.read(handle)\n",
        "    ids = record[\"IdList\"]\n",
        "    abstracts = []\n",
        "    for pmid in ids:\n",
        "        fetch = Entrez.efetch(db=\"pubmed\", id=pmid, rettype=\"abstract\", retmode=\"text\")\n",
        "        abstract_text = fetch.read()\n",
        "        abstracts.append(abstract_text)\n",
        "    return abstracts\n",
        "\n",
        "# ‚úÖ Step 5: Build vector store\n",
        "def build_vectorstore_from_articles(articles):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.create_documents(articles)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# ‚úÖ Step 6: Create Gemini-based QA system\n",
        "def create_qa_chain(vectorstore):\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
        "    return qa_chain\n",
        "\n",
        "# ‚úÖ Step 7: Ask your question\n",
        "def ask_health_question(query, qa_chain):\n",
        "    result = qa_chain(query)\n",
        "    print(\"\\nü©∫ Answer:\\n\")\n",
        "    print(result[\"result\"])\n",
        "    print(\"\\nüìö Sources:\")\n",
        "    for i, doc in enumerate(result[\"source_documents\"]):\n",
        "        print(f\"\\nSource {i+1}:\\n{doc.page_content[:500]}...\")\n",
        "\n",
        "# ‚úÖ Step 8: Run everything interactively\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = input(\"üí¨ Enter your medical/healthcare question: \")\n",
        "\n",
        "    print(\"\\nüîç Searching PubMed for related research...\")\n",
        "    articles = fetch_pubmed_articles(user_query, max_results=5)\n",
        "\n",
        "    if not articles:\n",
        "        print(\"‚ùå No articles found on this topic. Try a different question.\")\n",
        "    else:\n",
        "        print(\"üìö Building knowledge base from PubMed articles...\")\n",
        "        vectorstore = build_vectorstore_from_articles(articles)\n",
        "\n",
        "        print(\"ü§ñ Connecting to Gemini for answer generation...\")\n",
        "        qa_chain = create_qa_chain(vectorstore)\n",
        "\n",
        "        ask_health_question(user_query, qa_chain)\n",
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from Bio import Entrez\n",
        "# ‚úÖ Step 1: Install dependencies\n",
        "!pip install -q langchain faiss-cpu langchain-google-genai biopython google-generativeai\n",
        "\n",
        "# ‚úÖ Step 2: Import necessary libraries\n",
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "# ‚úÖ Step 1: Install dependencies\n",
        "!pip install -q langchain faiss-cpu langchain-google-genai biopython google-generativeai\n",
        "\n",
        "# ‚úÖ Step 2: Import necessary libraries\n",
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from Bio import Entrez\n",
        "# ‚úÖ Step 1: Install dependencies\n",
        "!pip install -q langchain faiss-cpu langchain-google-genai biopython google-generativeai\n",
        "\n",
        "# ‚úÖ Step 2: Import necessary libraries\n",
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from Bio import Entrez\n",
        "\n",
        "# ‚úÖ Step 3: API keys\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCgdbltYrrLWBO6dKVvfGfK-qvzMipTke4\" # Replace with your Gemini API key\n",
        "Entrez.email = \"prithika2004c@gmail.com\"  # Replace with your email for PubMed\n",
        "\n",
        "# ‚úÖ Step 4: Fetch articles from PubMed\n",
        "def fetch_pubmed_articles(query, max_results=5):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
        "    record = Entrez.read(handle)\n",
        "    ids = record[\"IdList\"]\n",
        "    abstracts = []\n",
        "    for pmid in ids:\n",
        "        fetch = Entrez.efetch(db=\"pubmed\", id=pmid, rettype=\"abstract\", retmode=\"text\")\n",
        "        abstract_text = fetch.read()\n",
        "        abstracts.append(abstract_text)\n",
        "    return abstracts\n",
        "\n",
        "# ‚úÖ Step 5: Build vector store\n",
        "def build_vectorstore_from_articles(articles):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.create_documents(articles)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# ‚úÖ Step 6: Create Gemini-based QA system\n",
        "def create_qa_chain(vectorstore):\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
        "    return qa_chain\n",
        "\n",
        "# ‚úÖ Step 7: Ask your question\n",
        "def ask_health_question(query, qa_chain):\n",
        "    result = qa_chain(query)\n",
        "    print(\"\\nü©∫ Answer:\\n\")\n",
        "    print(result[\"result\"])\n",
        "    print(\"\\nüìö Sources:\")\n",
        "    for i, doc in enumerate(result[\"source_documents\"]):\n",
        "        print(f\"\\nSource {i+1}:\\n{doc.page_content[:500]}...\")\n",
        "\n",
        "# ‚úÖ Step 8: Run everything interactively\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = input(\"üí¨ Enter your medical/healthcare question: \")\n",
        "\n",
        "    print(\"\\nüîç Searching PubMed for related research...\")\n",
        "    articles = fetch_pubmed_articles(user_query, max_results=5)\n",
        "\n",
        "    if not articles:\n",
        "        print(\"‚ùå No articles found on this topic. Try a different question.\")\n",
        "    else:\n",
        "        print(\"üìö Building knowledge base from PubMed articles...\")\n",
        "        vectorstore = build_vectorstore_from_articles(articles)\n",
        "\n",
        "        print(\"ü§ñ Connecting to Gemini for answer generation...\")\n",
        "        qa_chain = create_qa_chain(vectorstore)\n",
        "\n",
        "        ask_health_question(user_query, qa_chain)\n",
        "\n",
        "# ‚úÖ Step 4: Fetch articles from PubMed\n",
        "def fetch_pubmed_articles(query, max_results=5):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
        "    record = Entrez.read(handle)\n",
        "    ids = record[\"IdList\"]\n",
        "    abstracts = []\n",
        "    for pmid in ids:\n",
        "        fetch = Entrez.efetch(db=\"pubmed\", id=pmid, rettype=\"abstract\", retmode=\"text\")\n",
        "        abstract_text = fetch.read()\n",
        "        abstracts.append(abstract_text)\n",
        "    return abstracts\n",
        "\n",
        "# ‚úÖ Step 5: Build vector store\n",
        "def build_vectorstore_from_articles(articles):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.create_documents(articles)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# ‚úÖ Step 6: Create Gemini-based QA system\n",
        "def create_qa_chain(vectorstore):\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
        "    return qa_chain\n",
        "\n",
        "# ‚úÖ Step 7: Ask your question\n",
        "def ask_health_question(query, qa_chain):\n",
        "    result = qa_chain(query)\n",
        "    print(\"\\nü©∫ Answer:\\n\")\n",
        "    print(result[\"result\"])\n",
        "    print(\"\\nüìö Sources:\")\n",
        "    for i, doc in enumerate(result[\"source_documents\"]):\n",
        "        print(f\"\\nSource {i+1}:\\n{doc.page_content[:500]}...\")\n",
        "\n",
        "# ‚úÖ Step 8: Run everything interactively\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = input(\"üí¨ Enter your medical/healthcare question: \")\n",
        "\n",
        "    print(\"\\nüîç Searching PubMed for related research...\")\n",
        "    articles = fetch_pubmed_articles(user_query, max_results=5)\n",
        "\n",
        "    if not articles:\n",
        "        print(\"‚ùå No articles found on this topic. Try a different question.\")\n",
        "    else:\n",
        "        print(\"üìö Building knowledge base from PubMed articles...\")\n",
        "        vectorstore = build_vectorstore_from_articles(articles)\n",
        "\n",
        "        print(\"ü§ñ Connecting to Gemini for answer generation...\")\n",
        "        qa_chain = create_qa_chain(vectorstore)\n",
        "\n",
        "        ask_health_question(user_query, qa_chain)\n",
        "\n",
        "# ‚úÖ Step 4: Fetch articles from PubMed\n",
        "def fetch_pubmed_articles(query, max_results=5):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
        "    record = Entrez.read(handle)\n",
        "    ids = record[\"IdList\"]\n",
        "    abstracts = []\n",
        "    for pmid in ids:\n",
        "        fetch = Entrez.efetch(db=\"pubmed\", id=pmid, rettype=\"abstract\", retmode=\"text\")\n",
        "        abstract_text = fetch.read()\n",
        "        abstracts.append(abstract_text)\n",
        "    return abstracts\n",
        "\n",
        "# ‚úÖ Step 5: Build vector store\n",
        "def build_vectorstore_from_articles(articles):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.create_documents(articles)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# ‚úÖ Step 6: Create Gemini-based QA system\n",
        "def create_qa_chain(vectorstore):\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
        "    return qa_chain\n",
        "\n",
        "# ‚úÖ Step 7: Ask your question\n",
        "def ask_health_question(query, qa_chain):\n",
        "    result = qa_chain(query)\n",
        "    print(\"\\nü©∫ Answer:\\n\")\n",
        "    print(result[\"result\"])\n",
        "    print(\"\\nüìö Sources:\")\n",
        "    for i, doc in enumerate(result[\"source_documents\"]):\n",
        "        print(f\"\\nSource {i+1}:\\n{doc.page_content[:500]}...\")\n",
        "\n",
        "# ‚úÖ Step 8: Run everything interactively\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = input(\"üí¨ Enter your medical/healthcare question: \")\n",
        "\n",
        "    print(\"\\nüîç Searching PubMed for related research...\")\n",
        "    articles = fetch_pubmed_articles(user_query, max_results=5)\n",
        "\n",
        "    if not articles:\n",
        "        print(\"‚ùå No articles found on this topic. Try a different question.\")\n",
        "    else:\n",
        "        print(\"üìö Building knowledge base from PubMed articles...\")\n",
        "        vectorstore = build_vectorstore_from_articles(articles)\n",
        "\n",
        "        print(\"ü§ñ Connecting to Gemini for answer generation...\")\n",
        "        qa_chain = create_qa_chain(vectorstore)\n",
        "\n",
        "        ask_health_question(user_query, qa_chain)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9ObUF/5MnVITDj7UwRNOR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}